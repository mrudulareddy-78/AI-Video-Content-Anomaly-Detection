# Violence Detection Web App - Complete Guide

## What Was Built

A full-stack web application that detects violence in videos using AI, with a confidence-aware three-tier decision system (BLOCK/REVIEW/APPROVE) based on both violence score AND model confidence.

**Key Features:**
- üé• Upload videos or analyze YouTube URLs (including Shorts)
- üß† AI model analyzes 16-frame sequences using MobileNetV2 + LSTM
- üìä Confidence-aware decisions instead of binary SAFE/UNSAFE
- üéØ Three-tier system: BLOCK (clear violence), REVIEW (uncertain), APPROVE (safe)
- ‚ú® Drag-and-drop UI with smooth animations
- üì± Responsive design for all devices

---

## Tech Stack

### Backend
- **Framework:** FastAPI (Python)
- **Model:** `final_violence_model.keras` (MobileNetV2 + Bidirectional LSTM)
- **Video Processing:** OpenCV, TensorFlow/Keras
- **YouTube Download:** yt-dlp (with 60s timeout + 5 retries)
- **Port:** 8000

### Frontend
- **Framework:** React 18 with Vite 7.3.1
- **Styling:** Tailwind CSS
- **HTTP Client:** Axios
- **Port:** 5173

### Model Architecture
- **Input:** 16 frames √ó 64√ó64 pixels √ó 3 channels
- **Model:** MobileNetV2 feature extractor ‚Üí Bidirectional LSTM
- **Output:** Violence score (0-100%) + confidence percentage

---

## How to Use

### 1. Start the Backend

```bash
cd c:\Users\rr2k1\OneDrive\Desktop\prism
venv\Scripts\python.exe backend/main.py
```

Expected output:
```
‚úì Model architecture rebuilt and weights loaded from final_violence_model.keras
INFO: Uvicorn running on http://0.0.0.0:8000
```

### 2. Start the Frontend

In a new terminal:
```bash
cd c:\Users\rr2k1\OneDrive\Desktop\prism\frontend
npm run dev
```

Expected output:
```
VITE v7.3.1 ready in 360 ms
‚ûú Local: http://localhost:5173/
```

### 3. Open the App

Navigate to `http://localhost:5173/` in your browser.

---

## Using the Application

### Upload a Video
1. Click the **"Upload Video"** tab
2. Drag and drop a video file OR click to select
3. Click **"Analyze Video"** button
4. Results appear with violence score, confidence, and recommendation

### Analyze YouTube Video
1. Click the **"YouTube URL"** tab
2. Paste a YouTube URL (supports regular videos and Shorts)
3. Click **"Analyze Video"** button
4. App downloads and analyzes the video
5. Results appear with recommendation

### Understanding Results

The app shows:
- **üö´ BLOCK** (Red) - High confidence violence detected
- **‚ö†Ô∏è REVIEW** (Orange) - Borderline case, manual review needed
- **‚úÖ APPROVE** (Green) - Safe content with high confidence

Each result includes:
- Violence score (0-100%)
- Confidence level (HIGH/MEDIUM/LOW)
- Reasoning explanation
- Frames analyzed count

### Learn the System

Click **"‚ÑπÔ∏è How does the analysis work?"** to expand the InfoPanel and see:
- Decision logic for each confidence level
- Threshold values for all three tiers
- Key insights about the system
- Real-world example scenarios

---

## API Endpoints

### 1. Health Check
```
GET http://localhost:8000/
```

### 2. Upload Video
```
POST http://localhost:8000/api/analyze/upload
Content-Type: multipart/form-data

Body: form data with 'file' field
```

**Response:**
```json
{
  "score": 61.1,
  "verdict": "Violence Detected",
  "confidence": 22.18,
  "confidence_level": "LOW",
  "recommended_action": "REVIEW",
  "reasoning": "Borderline score with low confidence suggests sports/action content...",
  "frames_analyzed": 16
}
```

### 3. Analyze YouTube Video
```
POST http://localhost:8000/api/analyze/youtube
Content-Type: application/json

Body: {
  "url": "https://www.youtube.com/watch?v=..."
}
```

**Response:** Same as upload (7 fields)

---

## Decision Logic

### High Confidence (‚â•70%)
- Violence score > 46% ‚Üí **BLOCK üö´**
- Violence score ‚â§ 46% ‚Üí **APPROVE ‚úÖ**

### Medium Confidence (40-70%)
- Violence score > 60% ‚Üí **REVIEW ‚ö†Ô∏è**
- Violence score 35-60% ‚Üí **REVIEW ‚ö†Ô∏è**
- Violence score < 35% ‚Üí **APPROVE ‚úÖ**

### Low Confidence (<40%)
- Violence score > 55% ‚Üí **REVIEW ‚ö†Ô∏è** (likely sports/action)
- Violence score 40-55% ‚Üí **REVIEW ‚ö†Ô∏è** (uncertain)
- Violence score < 40% ‚Üí **APPROVE ‚úÖ**

---

## Project Structure

```
prism/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI server with all endpoints
‚îÇ   ‚îî‚îÄ‚îÄ final_violence_model.keras  # AI model
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx          # Main React component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.jsx         # Entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ VideoUpload.jsx      # Drag-drop upload
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ YouTubeInput.jsx     # YouTube URL input
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Results.jsx          # Results display
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ InfoPanel.jsx        # Decision logic explanation
‚îÇ   ‚îú‚îÄ‚îÄ index.html           # HTML template
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.js       # Vite configuration
‚îÇ   ‚îî‚îÄ‚îÄ package.json         # Dependencies
‚îú‚îÄ‚îÄ README.md                # Original project readme
‚îú‚îÄ‚îÄ GUIDE.md                 # This file
‚îî‚îÄ‚îÄ venv/                    # Python virtual environment
```

---

## Troubleshooting

### Backend Won't Start
**Error:** `Cannot convert '16' to a shape`
- **Fix:** Backend automatically rebuilds the model architecture. Just restart.

### YouTube Download Timeout
**Error:** `Read timed out`
- **Fix:** App retries 5 times with 60-second timeout. Try again or use smaller video.

### Frontend Shows Blank Page
**Error:** `http://localhost:5173 shows nothing`
- **Fix:** Check that Vite dev server is running (should see "Ready in XXms" in terminal)

### CORS Errors
**Error:** `blocked by CORS policy`
- **Fix:** Backend has CORS enabled for localhost:5173. Restart both servers if needed.

---

## Features Explained

### Confidence-Aware System
Instead of just saying "SAFE" or "UNSAFE", the system considers:
1. **Violence Score** - How much violence does the AI detect? (0-100%)
2. **Confidence** - How sure is the AI? (0-100%)

This means:
- A 60% violence score with HIGH confidence ‚Üí BLOCK (clear violence)
- A 60% violence score with LOW confidence ‚Üí REVIEW (might be sports)
- A 60% violence score with MEDIUM confidence ‚Üí REVIEW (needs human judgment)

### Why It Matters
The system distinguishes between:
- ‚úÖ Sports fights (low confidence, high score ‚Üí REVIEW)
- üö´ Assault videos (high confidence, high score ‚Üí BLOCK)
- ‚úÖ Normal content (high confidence, low score ‚Üí APPROVE)

### Three-Tier Actions
- **BLOCK:** Auto-reject, violates policy
- **REVIEW:** Flag for human moderator
- **APPROVE:** Auto-accept, safe content

---

## Model Information

- **Type:** Sequence-based neural network
- **Input:** 16 consecutive video frames (64√ó64 RGB)
- **Feature Extractor:** MobileNetV2 (efficient CNN)
- **Temporal Analysis:** Bidirectional LSTM (understands context)
- **Training Data:** Violence detection datasets
- **Output:** Binary classification with confidence

The model is small enough to run on CPU but can use GPU if available.

---

## Performance Notes

- **Average analysis time:** 2-5 seconds per video
- **Video frame limit:** 16 frames analyzed
- **YouTube download time:** 5-30 seconds depending on video length
- **Memory usage:** ~500MB for model + processing
- **Storage:** Model file is ~40MB

---

## Next Steps / Enhancements

Optional future improvements:
1. Add database to track decision history
2. Create admin dashboard for REVIEW-tier content
3. Implement feedback loop to improve model
4. Add batch processing for multiple videos
5. Deploy to production (AWS, Azure, etc.)
6. Add analytics dashboard
7. Implement rate limiting and authentication

---

## Support

For issues:
1. Check terminal output for error messages
2. Ensure both servers are running
3. Clear browser cache (Ctrl+Shift+Delete)
4. Restart both backend and frontend servers
5. Check that ports 8000 and 5173 are available

---

**Version:** 1.0  
**Date:** February 1, 2026  
**Status:** Production Ready ‚úÖ
